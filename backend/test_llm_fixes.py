#!/usr/bin/env python3
"""
Teste para verificar as correÃ§Ãµes no LLM Service
/-HALL-DEV Backend
"""

import asyncio
import os
from llm_service import LLMService, LLMCache
from schemas import LLMRequest, ChatMessage, MessageRole

async def test_api_key_validation():
    """Testa validaÃ§Ã£o da API key"""
    print("ğŸ§ª Testando validaÃ§Ã£o da API key...")
    
    # Simular ambiente sem API key
    original_key = os.getenv("GROQ_API_KEY")
    os.environ.pop("GROQ_API_KEY", None)
    
    try:
        # Deve falhar ao criar instÃ¢ncia sem API key
        service = LLMService()
        print("âŒ Erro: Deveria ter falhado sem API key")
    except ValueError as e:
        print(f"âœ… ValidaÃ§Ã£o funcionando: {e}")
    finally:
        # Restaurar API key
        if original_key:
            os.environ["GROQ_API_KEY"] = original_key

def test_cache_performance():
    """Testa performance do cache otimizado"""
    print("\nğŸ§ª Testando performance do cache...")
    
    cache = LLMCache(max_size=5, ttl_hours=1)
    
    # Adicionar itens
    for i in range(10):
        cache.set(f"key_{i}", f"value_{i}")
    
    print(f"âœ… Cache size apÃ³s adicionar 10 itens: {len(cache.cache)}")
    print(f"âœ… Cache max_size: {cache.max_size}")
    
    # Testar LRU
    cache.get("key_0")  # Deve mover para o final
    oldest_key = next(iter(cache.cache.keys()))
    print(f"âœ… Item mais antigo apÃ³s LRU: {oldest_key}")

async def test_message_validation():
    """Testa validaÃ§Ã£o de mensagens vazias"""
    print("\nğŸ§ª Testando validaÃ§Ã£o de mensagens...")
    
    # Restaurar API key para teste
    if not os.getenv("GROQ_API_KEY"):
        print("âš ï¸ GROQ_API_KEY nÃ£o definida, pulando teste de validaÃ§Ã£o")
        return
    
    try:
        service = LLMService()
        
        # Testar mensagem vazia
        request = LLMRequest(
            session_id="test",
            message="",
            context={"messages": []}
        )
        
        response = await service.generate_response(request)
        print(f"âœ… Resposta para mensagem vazia: {response.message[:50]}...")
        
        # Testar mensagem com espaÃ§os
        request.message = "   "
        response = await service.generate_response(request)
        print(f"âœ… Resposta para mensagem com espaÃ§os: {response.message[:50]}...")
        
    except Exception as e:
        print(f"âŒ Erro no teste de validaÃ§Ã£o: {e}")

def test_cache_cleanup():
    """Testa limpeza automÃ¡tica do cache"""
    print("\nğŸ§ª Testando limpeza automÃ¡tica do cache...")
    
    service = LLMService()
    
    # Simular cache cheio
    for i in range(600):  # Mais que max_size (500)
        service.cache.set(f"key_{i}", f"value_{i}")
    
    print(f"âœ… Cache size antes da limpeza: {len(service.cache.cache)}")
    
    # Executar limpeza automÃ¡tica
    service.auto_cleanup_cache()
    
    print(f"âœ… Cache size apÃ³s limpeza: {len(service.cache.cache)}")

async def main():
    """Executa todos os testes"""
    print("ğŸš€ Testando correÃ§Ãµes do LLM Service...\n")
    
    await test_api_key_validation()
    test_cache_performance()
    await test_message_validation()
    test_cache_cleanup()
    
    print("\nğŸ¯ Todos os testes concluÃ­dos!")

if __name__ == "__main__":
    asyncio.run(main())
