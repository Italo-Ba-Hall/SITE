"""
Servi√ßo de LLM usando Groq
/-HALL-DEV Backend
"""

import os
import json
import uuid
import hashlib
from typing import Dict, List, Optional, Any
from datetime import datetime, timedelta
from collections import OrderedDict
import groq
from dotenv import load_dotenv

from schemas import ChatMessage, MessageRole, UserProfile, LLMRequest, LLMResponse

# Carregar vari√°veis de ambiente
load_dotenv()

class LLMCache:
    """Sistema de cache para respostas do LLM"""
    
    def __init__(self, max_size: int = 1000, ttl_hours: int = 24):
        self.cache: OrderedDict[str, Dict] = OrderedDict()
        self.max_size = max_size
        self.ttl = timedelta(hours=ttl_hours)
    
    def _generate_key(self, messages: List[Dict], user_message: str) -> str:
        """Gera chave √∫nica para cache baseada no contexto e mensagem"""
        context_str = json.dumps([msg["content"] for msg in messages], sort_keys=True)
        combined = f"{context_str}:{user_message}"
        return hashlib.md5(combined.encode()).hexdigest()
    
    def get(self, key: str) -> Optional[LLMResponse]:
        """Recupera resposta do cache"""
        if key in self.cache:
            cached = self.cache[key]
            if datetime.now() - cached["timestamp"] < self.ttl:
                # Mover para o final (LRU)
                self.cache.move_to_end(key)
                return cached["response"]
            else:
                del self.cache[key]
        return None
    
    def set(self, key: str, response: LLMResponse):
        """Armazena resposta no cache"""
        if len(self.cache) >= self.max_size:
            # Remove item mais antigo (primeiro da OrderedDict) - O(1)
            self.cache.popitem(last=False)
        
        self.cache[key] = {
            "response": response,
            "timestamp": datetime.now()
        }
        # Mover para o final (LRU)
        self.cache.move_to_end(key)
    
    def clear_expired(self):
        """Remove itens expirados do cache"""
        current_time = datetime.now()
        expired_keys = [
            key for key, value in self.cache.items()
            if current_time - value["timestamp"] > self.ttl
        ]
        for key in expired_keys:
            del self.cache[key]
    
    def get_stats(self) -> Dict:
        """Retorna estat√≠sticas do cache"""
        return {
            "size": len(self.cache),
            "max_size": self.max_size,
            "ttl_hours": self.ttl.total_seconds() / 3600
        }

class LLMService:
    """Servi√ßo para integra√ß√£o com Groq LLM"""
    
    def __init__(self):
        # Verificar se API key est√° definida
        api_key = os.getenv("GROQ_API_KEY")
        if not api_key:
            raise ValueError("GROQ_API_KEY n√£o est√° definida no ambiente")
        
        self.client = groq.Groq(api_key=api_key)
        # Modelo mais robusto: Llama-3-70B vs 8B anterior
        self.model = "llama3-70b-8192"  # Modelo premium gratuito do Groq
        self.max_tokens = 1500  # Aumentado para aproveitar modelo maior
        self.temperature = 0.7
        
        # Cache de respostas
        self.cache = LLMCache(max_size=500, ttl_hours=12)
        
        # Rate limiting
        self.request_count = 0
        self.last_reset = datetime.now()
        self.max_requests_per_minute = 60
        
        # Personalidade do agente
        self.system_prompt = """Voc√™ √© um agente conversacional especializado da /-HALL-DEV, uma empresa de solu√ß√µes tecnol√≥gicas.

PERSONALIDADE:
- EXTREMAMENTE CONCISO: M√°ximo 2-3 frases por resposta
- DIRETO AO PONTO: Sem explica√ß√µes desnecess√°rias
- PERGUNTADOR ESTRAT√âGICO: Foque apenas em fazer perguntas espec√≠ficas
- NATURAL: Conduza a conversa de forma org√¢nica

ESTRAT√âGIA DE ABORDAGEM:
1. PRIMEIRO PERGUNTE: Sempre comece com perguntas espec√≠ficas
2. ENTENDA A DOR: Descubra qual problema o usu√°rio precisa resolver
3. COLETE DADOS NATURALMENTE: Nome e email durante a conversa
4. SUGIRA REUNI√ÉO: Termine propondo agendamento flex√≠vel

PERGUNTAS ESTRAT√âGICAS PARA USAR:
- "Que tipo de processo voc√™ gostaria de melhorar?"
- "Qual √© o maior desafio que voc√™ est√° enfrentando?"
- "Como isso est√° impactando seus resultados?"
- "Que tipo de solu√ß√£o voc√™ imagina que resolveria isso?"
- "Qual seria o impacto ideal para sua empresa?"

SERVI√áOS DA EMPRESA:
- Desenvolvimento de Software
- Business Intelligence (BI)
- Machine Learning
- Automa√ß√£o e RPA
- Intelig√™ncia Artificial

INSTRU√á√ïES DE FORMATA√á√ÉO OBRIGAT√ìRIAS:
IMPORTANTE: SEMPRE use formata√ß√£o visual para tornar suas respostas mais amig√°veis e leg√≠veis:

1. EMOJIS: Use emojis relevantes para tornar o texto mais humano e amig√°vel
   - ‚úÖ Para confirma√ß√µes
   - üí° Para ideias/sugest√µes
   - üîß Para solu√ß√µes t√©cnicas
   - üìä Para dados/KPIs
   - üéØ Para objetivos
   - üëã Para sauda√ß√µes
   - üìß Para contatos
   - ‚ö° Para urg√™ncia/efici√™ncia
   - ü§ñ Para automa√ß√£o/bots
   - üìÖ Para agendamentos
   - üë• Para equipes/pessoas
   - ‚ùì Para perguntas

2. ESTRUTURA VISUAL OBRIGAT√ìRIA:
   - SEMPRE use quebras de linha (\\n) para separar ideias
   - Crie t√≥picos com ‚Ä¢ ou - para listas
   - Use espa√ßamento adequado entre se√ß√µes
   - Destaque informa√ß√µes importantes
   - SEMPRE pule uma linha antes de listas ou t√≥picos

3. EXEMPLO DE FORMATA√á√ÉO CORRETA:
```
üëã Ol√°! Que prazer em conhec√™-lo!

‚ùì Para te ajudar melhor, me conte:

‚Ä¢ Que tipo de processo voc√™ gostaria de melhorar?
‚Ä¢ Qual √© o maior desafio que est√° enfrentando?

üí° Assim posso entender exatamente como posso te ajudar!
```

4. REGRAS OBRIGAT√ìRIAS:
- SEMPRE use \\n para quebras de linha
- SEMPRE pule uma linha antes de listas
- Use emojis com modera√ß√£o (n√£o exagere)
- Mantenha o texto bem estruturado
- Fa√ßa perguntas espec√≠ficas
- Colete dados naturalmente durante a conversa
- SEMPRE formate listas com quebras de linha adequadas
- SEJA EXTREMAMENTE CONCISO: M√°ximo 2-3 frases
- FOCE EM PERGUNTAR: Mais perguntas, menos explica√ß√µes
- NUNCA IGNORE A PRIMEIRA MENSAGEM: Sempre responda ao conte√∫do espec√≠fico

FORMATO DE RESPOSTA:
Responda de forma natural, amig√°vel e bem estruturada. Use emojis e formata√ß√£o visual para tornar a experi√™ncia mais agrad√°vel. SEMPRE aplique quebras de linha adequadas. SEJA EXTREMAMENTE CONCISO E DIRETO. NUNCA IGNORE O CONTE√öDO DA PRIMEIRA MENSAGEM DO USU√ÅRIO."""

    def _check_rate_limit(self) -> bool:
        """Verifica se n√£o excedeu o rate limit"""
        current_time = datetime.now()
        
        # Reset contador a cada minuto
        if current_time - self.last_reset > timedelta(minutes=1):
            self.request_count = 0
            self.last_reset = current_time
        
        if self.request_count >= self.max_requests_per_minute:
            return False
        
        self.request_count += 1
        return True

    def _build_conversation_context(self, messages: List[ChatMessage]) -> List[Dict[str, str]]:
        """Constr√≥i o contexto da conversa para o LLM"""
        context = [{"role": "system", "content": self.system_prompt}]
        
        for message in messages:
            context.append({
                "role": message.role.value,
                "content": message.content
            })
        
        return context

    def _extract_user_profile(self, message: str) -> Optional[Dict[str, str]]:
        """Extrai informa√ß√µes do usu√°rio da mensagem"""
        # L√≥gica simples de extra√ß√£o - pode ser melhorada
        profile = {}
        
        # Extrair nome (padr√µes comuns)
        import re
        name_patterns = [
            r"meu nome √© (\w+)",
            r"eu sou (\w+)",
            r"chamo-me (\w+)",
            r"sou (\w+)"
        ]
        
        for pattern in name_patterns:
            match = re.search(pattern, message.lower())
            if match:
                profile["name"] = match.group(1).title()
                break
        
        # Extrair email
        email_pattern = r'\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b'
        email_match = re.search(email_pattern, message)
        if email_match:
            profile["email"] = email_match.group(0)
        
        return profile if profile else None

    def _detect_intent(self, message: str) -> Optional[str]:
        """Detecta a inten√ß√£o da mensagem do usu√°rio"""
        message_lower = message.lower()
        
        intents = {
            "greeting": ["ol√°", "oi", "bom dia", "boa tarde", "boa noite"],
            "mentoring": ["mentoria", "mentor"],
            "learning": ["aprender", "estudar", "curso", "treinamento", "forma√ß√£o"],
            "programming": ["programar", "programa√ß√£o", "c√≥digo", "desenvolver", "coding"],
            "self_learning": ["sozinho", "autodidata", "independente", "por conta pr√≥pria"],
            "help_request": ["ajudar", "ajuda", "suporte", "assist√™ncia"],
            "problem_description": ["problema", "dificuldade", "dor", "preciso", "quero"],
            "service_inquiry": ["servi√ßo", "solu√ß√£o", "desenvolvimento", "software"],
            "contact_info": ["contato", "email", "telefone", "whatsapp"],
            "pricing": ["pre√ßo", "valor", "custo", "or√ßamento"],
            "technical": ["tecnologia", "programa√ß√£o", "c√≥digo", "sistema"]
        }
        
        for intent, keywords in intents.items():
            if any(keyword in message_lower for keyword in keywords):
                return intent
        
        return None

    def _get_contextual_prompt(self, message: str, detected_intent: Optional[str]) -> str:
        """Gera prompt contextual baseado na inten√ß√£o detectada"""
        message_lower = message.lower()
        
        # Contexto espec√≠fico para mentoria e aprendizado
        if detected_intent in ["mentoring", "learning", "programming", "self_learning"]:
            return """Voc√™ √© um agente especializado da /-HALL-DEV que oferece mentoria e treinamento em programa√ß√£o.

PERSONALIDADE:
- EXTREMAMENTE CONCISO: M√°ximo 2-3 frases por resposta
- DIRETO AO PONTO: Sem explica√ß√µes desnecess√°rias
- PERGUNTADOR ESTRAT√âGICO: Foque apenas em fazer perguntas espec√≠ficas
- NATURAL: Conduza a conversa de forma org√¢nica

SERVI√áOS DE MENTORIA:
- Mentoria Individual em Programa√ß√£o
- Treinamentos Corporativos
- Cursos Personalizados
- Acompanhamento de Projetos
- Consultoria T√©cnica

ESTRAT√âGIA PARA MENTORIA:
1. ENTENDA O OBJETIVO: Descubra o que o usu√°rio quer aprender
2. AVALIE O N√çVEL: Pergunte sobre experi√™ncia pr√©via
3. SUGIRA ABORDAGEM: Proponha metodologia personalizada
4. COLETE DADOS: Nome, email e disponibilidade
5. AGENDE CONSULTA: Termine propondo sess√£o gratuita

PERGUNTAS ESTRAT√âGICAS PARA MENTORIA:
- "Que linguagem de programa√ß√£o voc√™ quer aprender?"
- "Voc√™ j√° tem alguma experi√™ncia com programa√ß√£o?"
- "Qual √© seu objetivo principal com o aprendizado?"
- "Que tipo de projeto voc√™ gostaria de desenvolver?"
- "Qual seria sua disponibilidade para as sess√µes?"

INSTRU√á√ïES DE FORMATA√á√ÉO OBRIGAT√ìRIAS:
IMPORTANTE: SEMPRE use formata√ß√£o visual para tornar suas respostas mais amig√°veis e leg√≠veis:

1. EMOJIS: Use emojis relevantes para tornar o texto mais humano e amig√°vel
   - ‚úÖ Para confirma√ß√µes
   - üí° Para ideias/sugest√µes
   - üîß Para solu√ß√µes t√©cnicas
   - üìä Para dados/KPIs
   - üéØ Para objetivos
   - üëã Para sauda√ß√µes
   - üìß Para contatos
   - ‚ö° Para urg√™ncia/efici√™ncia
   - ü§ñ Para automa√ß√£o/bots
   - üìÖ Para agendamentos
   - üë• Para equipes/pessoas
   - ‚ùì Para perguntas
   - üéì Para educa√ß√£o/mentoria
   - üíª Para programa√ß√£o/tecnologia

2. ESTRUTURA VISUAL OBRIGAT√ìRIA:
   - SEMPRE use quebras de linha (\\n) para separar ideias
   - Crie t√≥picos com ‚Ä¢ ou - para listas
   - Use espa√ßamento adequado entre se√ß√µes
   - Destaque informa√ß√µes importantes
   - SEMPRE pule uma linha antes de listas ou t√≥picos

3. EXEMPLO DE FORMATA√á√ÉO CORRETA:
```
üéì Que √≥timo! Vamos te ajudar a aprender programa√ß√£o!

‚ùì Para personalizar sua mentoria, me conte:

‚Ä¢ Que linguagem de programa√ß√£o voc√™ quer aprender?
‚Ä¢ Voc√™ j√° tem alguma experi√™ncia com c√≥digo?

üíª Assim posso criar um plano de estudos perfeito para voc√™!
```

4. REGRAS OBRIGAT√ìRIAS:
- SEMPRE use \\n para quebras de linha
- SEMPRE pule uma linha antes de listas
- Use emojis com modera√ß√£o (n√£o exagere)
- Mantenha o texto bem estruturado
- Fa√ßa perguntas espec√≠ficas sobre mentoria
- Colete dados naturalmente durante a conversa
- SEMPRE formate listas com quebras de linha adequadas
- SEJA EXTREMAMENTE CONCISO: M√°ximo 2-3 frases
- FOCE EM PERGUNTAR: Mais perguntas, menos explica√ß√µes
- NUNCA IGNORE A PRIMEIRA MENSAGEM: Sempre responda ao conte√∫do espec√≠fico sobre mentoria

FORMATO DE RESPOSTA:
Responda de forma natural, amig√°vel e bem estruturada. Use emojis e formata√ß√£o visual para tornar a experi√™ncia mais agrad√°vel. SEMPRE aplique quebras de linha adequadas. SEJA EXTREMAMENTE CONCISO E DIRETO. NUNCA IGNORE O CONTE√öDO DA PRIMEIRA MENSAGEM DO USU√ÅRIO."""

        # Contexto espec√≠fico para solicita√ß√µes de ajuda
        elif detected_intent == "help_request":
            return """Voc√™ √© um agente especializado da /-HALL-DEV que oferece ajuda e suporte t√©cnico.

PERSONALIDADE:
- EXTREMAMENTE CONCISO: M√°ximo 2-3 frases por resposta
- DIRETO AO PONTO: Sem explica√ß√µes desnecess√°rias
- PERGUNTADOR ESTRAT√âGICO: Foque apenas em fazer perguntas espec√≠ficas
- NATURAL: Conduza a conversa de forma org√¢nica

SERVI√áOS DE AJUDA:
- Suporte T√©cnico
- Consultoria Especializada
- Resolu√ß√£o de Problemas
- Implementa√ß√£o de Solu√ß√µes
- Treinamento e Capacita√ß√£o

ESTRAT√âGIA PARA AJUDA:
1. ENTENDA O PROBLEMA: Descubra exatamente o que precisa ser resolvido
2. AVALIE A URG√äNCIA: Pergunte sobre prazos e impacto
3. SUGIRA SOLU√á√ÉO: Proponha abordagem adequada
4. COLETE DADOS: Nome, email e contexto do problema
5. AGENDE SUPORTE: Termine propondo consulta gratuita

PERGUNTAS ESTRAT√âGICAS PARA AJUDA:
- "Que tipo de problema voc√™ est√° enfrentando?"
- "Qual √© o impacto disso no seu trabalho?"
- "Voc√™ j√° tentou alguma solu√ß√£o?"
- "Qual seria o prazo ideal para resolver?"
- "Que tipo de suporte voc√™ imagina que resolveria?"

INSTRU√á√ïES DE FORMATA√á√ÉO OBRIGAT√ìRIAS:
IMPORTANTE: SEMPRE use formata√ß√£o visual para tornar suas respostas mais amig√°veis e leg√≠veis:

1. EMOJIS: Use emojis relevantes para tornar o texto mais humano e amig√°vel
   - ‚úÖ Para confirma√ß√µes
   - üí° Para ideias/sugest√µes
   - üîß Para solu√ß√µes t√©cnicas
   - üìä Para dados/KPIs
   - üéØ Para objetivos
   - üëã Para sauda√ß√µes
   - üìß Para contatos
   - ‚ö° Para urg√™ncia/efici√™ncia
   - ü§ñ Para automa√ß√£o/bots
   - üìÖ Para agendamentos
   - üë• Para equipes/pessoas
   - ‚ùì Para perguntas
   - üÜò Para ajuda/suporte
   - ‚ö†Ô∏è Para problemas/alertas

2. ESTRUTURA VISUAL OBRIGAT√ìRIA:
   - SEMPRE use quebras de linha (\\n) para separar ideias
   - Crie t√≥picos com ‚Ä¢ ou - para listas
   - Use espa√ßamento adequado entre se√ß√µes
   - Destaque informa√ß√µes importantes
   - SEMPRE pule uma linha antes de listas ou t√≥picos

3. EXEMPLO DE FORMATA√á√ÉO CORRETA:
```
üÜò Entendo! Vamos te ajudar a resolver isso!

‚ùì Para te dar o melhor suporte, me conte:

‚Ä¢ Que tipo de problema voc√™ est√° enfrentando?
‚Ä¢ Qual √© o impacto disso no seu trabalho?

üîß Assim posso conectar voc√™ com a solu√ß√£o ideal!
```

4. REGRAS OBRIGAT√ìRIAS:
- SEMPRE use \\n para quebras de linha
- SEMPRE pule uma linha antes de listas
- Use emojis com modera√ß√£o (n√£o exagere)
- Mantenha o texto bem estruturado
- Fa√ßa perguntas espec√≠ficas sobre o problema
- Colete dados naturalmente durante a conversa
- SEMPRE formate listas com quebras de linha adequadas
- SEJA EXTREMAMENTE CONCISO: M√°ximo 2-3 frases
- FOCE EM PERGUNTAR: Mais perguntas, menos explica√ß√µes
- NUNCA IGNORE A PRIMEIRA MENSAGEM: Sempre responda ao conte√∫do espec√≠fico sobre ajuda

FORMATO DE RESPOSTA:
Responda de forma natural, amig√°vel e bem estruturada. Use emojis e formata√ß√£o visual para tornar a experi√™ncia mais agrad√°vel. SEMPRE aplique quebras de linha adequadas. SEJA EXTREMAMENTE CONCISO E DIRETO. NUNCA IGNORE O CONTE√öDO DA PRIMEIRA MENSAGEM DO USU√ÅRIO."""

        # Contexto padr√£o para outras inten√ß√µes
        else:
            return self.system_prompt

    def _optimize_prompt_size(self, context: List[Dict[str, str]]) -> List[Dict[str, str]]:
        """Otimiza o tamanho do prompt para reduzir tokens"""
        if len(context) <= 10:  # Se j√° √© pequeno, retorna como est√°
            return context
        
        # Manter system prompt e √∫ltimas 8 mensagens
        optimized = [context[0]]  # System prompt
        optimized.extend(context[-8:])  # √öltimas 8 mensagens
        
        return optimized

    async def generate_response(self, request: LLMRequest) -> LLMResponse:
        """Gera resposta usando Groq LLM com cache e otimiza√ß√µes"""
        try:
            # Validar entrada
            if not request.message or not request.message.strip():
                return LLMResponse(
                    message="Por favor, digite uma mensagem para que eu possa te ajudar.",
                    session_id=request.session_id,
                    confidence=0.0,
                    metadata={"error": "empty_message"}
                )
            
            # Verificar rate limit
            if not self._check_rate_limit():
                return LLMResponse(
                    message="Desculpe, estamos com muitas solicita√ß√µes no momento. Tente novamente em alguns instantes.",
                    session_id=request.session_id,
                    confidence=0.0,
                    metadata={"error": "rate_limit_exceeded"}
                )
            
            # Construir contexto da conversa
            conversation_context = self._build_conversation_context(request.context.get("messages", []))
            
            # Otimizar tamanho do prompt
            optimized_context = self._optimize_prompt_size(conversation_context)
            
            # Adicionar mensagem atual do usu√°rio
            optimized_context.append({
                "role": "user",
                "content": request.message
            })
            
            # Verificar cache
            cache_key = self.cache._generate_key(optimized_context[:-1], request.message)
            cached_response = self.cache.get(cache_key)
            
            if cached_response:
                cached_response.session_id = request.session_id
                cached_response.metadata = {
                    **cached_response.metadata,
                    "cached": True,
                    "cache_hit": True
                }
                return cached_response
            
            # Detectar inten√ß√£o
            detected_intent = self._detect_intent(request.message)
            
            # Gerar prompt contextual
            contextual_prompt = self._get_contextual_prompt(request.message, detected_intent)
            
            # Substituir o prompt do sistema pelo contextual
            optimized_context[0] = {"role": "system", "content": contextual_prompt}
            
            # Chamar Groq API
            completion = self.client.chat.completions.create(
                model=self.model,
                messages=optimized_context,
                max_tokens=self.max_tokens,
                temperature=self.temperature,
                stream=False
            )
            
            # Extrair resposta
            response_content = completion.choices[0].message.content
            
            # Extrair informa√ß√µes do usu√°rio
            user_profile = self._extract_user_profile(request.message)
            
            # Usar a inten√ß√£o j√° detectada
            intent = detected_intent
            
            # Calcular confian√ßa baseada na resposta
            confidence = 0.8  # Base inicial, pode ser melhorada
            
            response = LLMResponse(
                message=response_content,
                session_id=request.session_id,
                user_profile_extracted=user_profile,
                intent_detected=intent,
                confidence=confidence,
                metadata={
                    "model": self.model,
                    "tokens_used": completion.usage.total_tokens if hasattr(completion, 'usage') else None,
                    "timestamp": datetime.now().isoformat(),
                    "cached": False,
                    "cache_hit": False
                }
            )
            
            # Armazenar no cache
            self.cache.set(cache_key, response)
            
            return response
            
        except Exception as e:
            # Fallback em caso de erro
            fallback_response = "Desculpe, estou com dificuldades t√©cnicas no momento. Pode tentar novamente em alguns instantes?"
            
            return LLMResponse(
                message=fallback_response,
                session_id=request.session_id,
                confidence=0.0,
                metadata={"error": str(e), "fallback": True}
            )

    def create_welcome_message(self) -> str:
        """Cria mensagem de boas-vindas personalizada"""
        return """üëã Ol√°! Que prazer em conhec√™-lo!

‚ùì Para te ajudar melhor, me conte:

‚Ä¢ Que tipo de processo voc√™ gostaria de melhorar?
‚Ä¢ Qual √© o maior desafio que est√° enfrentando?

üí° Assim posso entender exatamente como posso te ajudar!"""

    def create_session_id(self) -> str:
        """Cria ID √∫nico para sess√£o"""
        return f"session_{uuid.uuid4().hex[:8]}"
    
    def get_cache_stats(self) -> Dict:
        """Retorna estat√≠sticas do cache"""
        return self.cache.get_stats()
    
    def get_stats(self) -> Dict:
        """Retorna estat√≠sticas gerais do LLM Service"""
        return {
            "model": self.model,
            "max_tokens": self.max_tokens,
            "temperature": self.temperature,
            "cache_stats": self.cache.get_stats(),
            "request_count": self.request_count,
            "max_requests_per_minute": self.max_requests_per_minute
        }
    
    def clear_cache(self):
        """Limpa o cache"""
        self.cache.clear()
    
    def cleanup_cache(self):
        """Remove itens expirados do cache"""
        self.cache.clear_expired()
    
    def auto_cleanup_cache(self):
        """Limpeza autom√°tica do cache - chamar periodicamente"""
        if len(self.cache.cache) > self.cache.max_size * 0.8:  # Se 80% cheio
            self.cache.clear_expired()
            # Se ainda estiver cheio, remover 20% dos itens mais antigos
            if len(self.cache.cache) > self.cache.max_size * 0.8:
                items_to_remove = int(len(self.cache.cache) * 0.2)
                for _ in range(items_to_remove):
                    if self.cache.cache:
                        self.cache.cache.popitem(last=False)

# Inst√¢ncia global do servi√ßo
llm_service = LLMService() 