#!/usr/bin/env python3
"""
Teste para verificar se o bot responde ao conteÃºdo da primeira mensagem
/-HALL-DEV Backend
"""

import asyncio

from llm_service import llm_service
from schemas import ChatMessage, LLMRequest, MessageRole


async def test_first_message_response():
    """Testa se o bot responde ao conteÃºdo da primeira mensagem"""
    print("ğŸ§ª Testando resposta Ã  primeira mensagem...")

    # Simular primeira mensagem do usuÃ¡rio
    first_message = "Preciso de um sistema de automaÃ§Ã£o para minha empresa"

    # Criar contexto com mensagem de boas-vindas
    messages = [
        ChatMessage(
            role=MessageRole.ASSISTANT,
            content="ğŸ‘‹ OlÃ¡! Que prazer em conhecÃª-lo!\n\nâ“ Para te ajudar melhor, me conte:\n\nâ€¢ Que tipo de processo vocÃª gostaria de melhorar?\nâ€¢ Qual Ã© o maior desafio que estÃ¡ enfrentando?\n\nğŸ’¡ Assim posso entender exatamente como posso te ajudar!",
        )
    ]

    # Testar resposta para primeira mensagem especÃ­fica
    request = LLMRequest(
        session_id="test-first-message",
        message=first_message,
        context={"messages": messages},
    )

    try:
        response = await llm_service.generate_response(request)
        print(f"âœ… Resposta do LLM: {response.message}")

        # Verificar se a resposta menciona automaÃ§Ã£o
        if (
            "automaÃ§Ã£o" in response.message.lower()
            or "automatizaÃ§Ã£o" in response.message.lower()
        ):
            print("âœ… Bot respondeu ao conteÃºdo da primeira mensagem (automaÃ§Ã£o)")
        else:
            print("âš ï¸ Bot pode nÃ£o estar respondendo ao conteÃºdo especÃ­fico")

        # Verificar se Ã© conciso
        if len(response.message.split()) < 50:
            print("âœ… Resposta Ã© concisa")
        else:
            print("âš ï¸ Resposta pode estar muito longa")

    except Exception as e:
        print(f"âŒ Erro ao testar primeira mensagem: {e!s}")


async def test_generic_first_message():
    """Testa resposta para mensagem genÃ©rica"""
    print("\nğŸ§ª Testando resposta para mensagem genÃ©rica...")

    # Simular mensagem genÃ©rica
    generic_message = "OlÃ¡"

    # Criar contexto com mensagem de boas-vindas
    messages = [
        ChatMessage(
            role=MessageRole.ASSISTANT,
            content="ğŸ‘‹ OlÃ¡! Que prazer em conhecÃª-lo!\n\nâ“ Para te ajudar melhor, me conte:\n\nâ€¢ Que tipo de processo vocÃª gostaria de melhorar?\nâ€¢ Qual Ã© o maior desafio que estÃ¡ enfrentando?\n\nğŸ’¡ Assim posso entender exatamente como posso te ajudar!",
        )
    ]

    # Testar resposta para mensagem genÃ©rica
    request = LLMRequest(
        session_id="test-generic-message",
        message=generic_message,
        context={"messages": messages},
    )

    try:
        response = await llm_service.generate_response(request)
        print(f"âœ… Resposta do LLM: {response.message}")

        # Verificar se faz perguntas estratÃ©gicas
        if "?" in response.message:
            print("âœ… Bot faz perguntas estratÃ©gicas")
        else:
            print("âš ï¸ Bot pode nÃ£o estar fazendo perguntas")

    except Exception as e:
        print(f"âŒ Erro ao testar mensagem genÃ©rica: {e!s}")


async def main():
    """Executa os testes"""
    print("ğŸš€ Testando respostas do bot...\n")

    await test_first_message_response()
    await test_generic_first_message()

    print("\nğŸ¯ Testes concluÃ­dos!")


if __name__ == "__main__":
    asyncio.run(main())
